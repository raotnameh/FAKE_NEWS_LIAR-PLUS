{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import plot as plt\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "import cleaningtool as ct\n",
    "from helpers import *\n",
    "\n",
    "from model import *\n",
    "from data import *\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning = True\n",
    "## Define paths\n",
    "DATA_FOLDER = './data_1/'\n",
    "TRAIN_PATH = DATA_FOLDER + 'train.tsv'\n",
    "TEST_PATH = DATA_FOLDER + 'test.tsv'\n",
    "VALID_PATH = DATA_FOLDER + '/valid.tsv'\n",
    "\n",
    "train_data = load_data(TRAIN_PATH)\n",
    "test_data = load_data(TEST_PATH)\n",
    "valid_data = load_data(VALID_PATH)\n",
    "\n",
    "\n",
    "train_data = train_data[[\"statement\", \"label\"]]\n",
    "test_data = test_data[[\"statement\", \"label\"]]\n",
    "valid_data = valid_data[[\"statement\", \"label\"]]\n",
    "\n",
    "df_raw = pd.concat([train_data, test_data, valid_data], axis=0, sort=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before :- Says the Annies List political group supports third-trimester abortions on demand.\n",
      "\n",
      "after :- say list political group support abortion demand\n"
     ]
    }
   ],
   "source": [
    "if cleaning == True:\n",
    "    print(\"before :-\",df_raw[\"statement\"][0])\n",
    "    train_data = clean_data(train_data,\"statement\")\n",
    "    test_data = clean_data(test_data,\"statement\")\n",
    "    valid_data = clean_data(valid_data,\"statement\")\n",
    "    df_raw = clean_data(df_raw,'statement')\n",
    "    print()\n",
    "    print(\"after :-\", df_raw[\"statement\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentence to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_x, df_raw_y = sent_words(df_raw), sent_words(df_raw,label=True)\n",
    "x_train, y_train, x_val, y_val = sent_words(train_data), sent_words(train_data,label=True), sent_words(valid_data), sent_words(valid_data,label=True)\n",
    "x_test, y_test = sent_words(test_data), sent_words(test_data,label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train).reshape(len(x_train),1)\n",
    "y_train = np.array(y_train).reshape(len(x_train),1)\n",
    "x_test = np.array(x_test).reshape(len(x_test),1)\n",
    "y_test = np.array(y_test).reshape(len(x_test),1)\n",
    "x_val = np.array(x_val).reshape(len(x_val),1)\n",
    "y_val = np.array(y_val).reshape(len(x_val),1)\n",
    "\n",
    "train = np.concatenate((x_train,y_train),axis = 1)\n",
    "val = np.concatenate((x_val,y_val),axis = 1)\n",
    "test = np.concatenate((x_test,y_test),axis = 1)\n",
    "data_ = [train,val,test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = word_to_ix_(df_raw_x)\n",
    "label_to_ix = label_to_ix_(df_raw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3199, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_ix),len(label_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_word = OrderedDict((v,k) for k,v in word_to_ix.items())\n",
    "ix_to_label = OrderedDict((v,k) for k,v in label_to_ix.items())\n",
    "VOCAB_SIZE = len( word_to_ix )\n",
    "NUM_LABELS = len(set(label_to_ix.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = into_token(train,word_to_ix)\n",
    "test_ = into_token(test,word_to_ix)\n",
    "val_ = into_token(val,word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_ = np.concatenate((train_,val_),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('embed.p', 'rb') as fp:\n",
    "    embed = OrderedDict(pickle.load(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words found :- 3142\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 300\n",
    "matrix_len = len(word_to_ix.keys())\n",
    "weights_matrix = np.zeros((matrix_len, emb_dim))\n",
    "words_found = 0\n",
    "\n",
    "for i, word in enumerate(word_to_ix.keys()):\n",
    "    try: \n",
    "        weights_matrix[i] = embed[word]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
    "print(\"words found :-\",words_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix = torch.tensor(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional_ = True\n",
    "directions_ = 1\n",
    "\n",
    "if bidirectional_ == True:\n",
    "    directions_ = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change it's value as per classification task requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed layer is trainable or no :---- True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderRNN(\n",
       "  (embedding): Embedding(3199, 300)\n",
       "  (gru): GRU(300, 512, batch_first=True, bidirectional=True)\n",
       "  (linear1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (linear3): Linear(in_features=128, out_features=6, bias=True)\n",
       "  (drop): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = create_emb_layer(weights_matrix, non_trainable=False)\n",
    "print(\"embed layer is trainable or no :----\",embedding[0].weight.requires_grad)\n",
    "model = EncoderRNN(embedding,hidden_size=512,num_layers=1,directions=directions_,bidirectonal=bidirectional_,out=out_classes)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number : 1\n",
      "[1,  1024] loss: 1.848\n",
      "[1,  2048] loss: 1.613\n",
      "[1,  3072] loss: 1.452\n",
      "[1,  4096] loss: 1.504\n",
      "[1,  5120] loss: 1.397\n",
      "[1,  6144] loss: 1.406\n",
      "[1,  7168] loss: 1.338\n",
      "[1,  8192] loss: 1.390\n",
      "[1,  9216] loss: 1.345\n",
      "[1, 10240] loss: 1.333\n",
      "[1, 11264] loss: 2.065\n",
      "accuray while evaluating is : 21.081504702194355 %.\n",
      "epoch number : 2\n",
      "[2,  1024] loss: 1.376\n",
      "[2,  2048] loss: 1.195\n",
      "[2,  3072] loss: 1.147\n",
      "[2,  4096] loss: 1.207\n",
      "[2,  5120] loss: 1.206\n",
      "[2,  6144] loss: 1.174\n",
      "[2,  7168] loss: 1.164\n",
      "[2,  8192] loss: 1.206\n",
      "[2,  9216] loss: 1.169\n",
      "[2, 10240] loss: 1.152\n",
      "[2, 11264] loss: 1.903\n",
      "accuray while evaluating is : 26.489028213166144 %.\n",
      "epoch number : 3\n",
      "[3,  1024] loss: 1.215\n",
      "[3,  2048] loss: 1.079\n",
      "[3,  3072] loss: 1.031\n",
      "[3,  4096] loss: 1.053\n",
      "[3,  5120] loss: 1.126\n",
      "[3,  6144] loss: 1.067\n",
      "[3,  7168] loss: 1.053\n",
      "[3,  8192] loss: 1.121\n",
      "[3,  9216] loss: 1.069\n",
      "[3, 10240] loss: 1.017\n",
      "[3, 11264] loss: 1.842\n",
      "accuray while evaluating is : 27.11598746081505 %.\n",
      "epoch number : 4\n",
      "[4,  1024] loss: 1.130\n",
      "[4,  2048] loss: 0.970\n",
      "[4,  3072] loss: 0.958\n",
      "[4,  4096] loss: 0.973\n",
      "[4,  5120] loss: 1.040\n",
      "[4,  6144] loss: 0.972\n",
      "[4,  7168] loss: 0.961\n",
      "[4,  8192] loss: 1.017\n",
      "[4,  9216] loss: 0.978\n",
      "[4, 10240] loss: 0.944\n",
      "[4, 11264] loss: 1.795\n",
      "accuray while evaluating is : 28.369905956112852 %.\n",
      "epoch number : 5\n",
      "[5,  1024] loss: 1.007\n",
      "[5,  2048] loss: 0.886\n",
      "[5,  3072] loss: 0.852\n",
      "[5,  4096] loss: 0.915\n",
      "[5,  5120] loss: 0.947\n",
      "[5,  6144] loss: 0.874\n",
      "[5,  7168] loss: 0.850\n",
      "[5,  8192] loss: 0.943\n",
      "[5,  9216] loss: 0.874\n",
      "[5, 10240] loss: 0.854\n",
      "[5, 11264] loss: 1.711\n",
      "accuray while evaluating is : 32.445141065830725 %.\n",
      "epoch number : 6\n",
      "[6,  1024] loss: 0.910\n",
      "[6,  2048] loss: 0.794\n",
      "[6,  3072] loss: 0.761\n",
      "[6,  4096] loss: 0.806\n",
      "[6,  5120] loss: 0.874\n",
      "[6,  6144] loss: 0.812\n",
      "[6,  7168] loss: 0.772\n",
      "[6,  8192] loss: 0.877\n",
      "[6,  9216] loss: 0.773\n",
      "[6, 10240] loss: 0.760\n",
      "[6, 11264] loss: 1.666\n",
      "accuray while evaluating is : 35.9717868338558 %.\n",
      "epoch number : 7\n",
      "[7,  1024] loss: 0.819\n",
      "[7,  2048] loss: 0.717\n",
      "[7,  3072] loss: 0.703\n",
      "[7,  4096] loss: 0.729\n",
      "[7,  5120] loss: 0.781\n",
      "[7,  6144] loss: 0.726\n",
      "[7,  7168] loss: 0.696\n",
      "[7,  8192] loss: 0.751\n",
      "[7,  9216] loss: 0.673\n",
      "[7, 10240] loss: 0.698\n",
      "[7, 11264] loss: 1.602\n",
      "accuray while evaluating is : 39.42006269592476 %.\n",
      "epoch number : 8\n",
      "[8,  1024] loss: 0.740\n",
      "[8,  2048] loss: 0.654\n",
      "[8,  3072] loss: 0.629\n",
      "[8,  4096] loss: 0.636\n",
      "[8,  5120] loss: 0.688\n",
      "[8,  6144] loss: 0.645\n",
      "[8,  7168] loss: 0.615\n",
      "[8,  8192] loss: 0.667\n",
      "[8,  9216] loss: 0.619\n",
      "[8, 10240] loss: 0.592\n",
      "[8, 11264] loss: 1.491\n",
      "accuray while evaluating is : 43.73040752351097 %.\n",
      "epoch number : 9\n",
      "[9,  1024] loss: 0.619\n",
      "[9,  2048] loss: 0.561\n",
      "[9,  3072] loss: 0.577\n",
      "[9,  4096] loss: 0.580\n",
      "[9,  5120] loss: 0.601\n",
      "[9,  6144] loss: 0.575\n",
      "[9,  7168] loss: 0.555\n",
      "[9,  8192] loss: 0.606\n",
      "[9,  9216] loss: 0.516\n",
      "[9, 10240] loss: 0.546\n",
      "[9, 11264] loss: 1.407\n",
      "accuray while evaluating is : 46.47335423197492 %.\n",
      "epoch number : 10\n",
      "[10,  1024] loss: 0.568\n",
      "[10,  2048] loss: 0.518\n",
      "[10,  3072] loss: 0.503\n",
      "[10,  4096] loss: 0.505\n",
      "[10,  5120] loss: 0.620\n",
      "[10,  6144] loss: 0.548\n",
      "[10,  7168] loss: 0.628\n",
      "[10,  8192] loss: 0.608\n",
      "[10,  9216] loss: 0.521\n",
      "[10, 10240] loss: 0.563\n",
      "[10, 11264] loss: 1.382\n",
      "accuray while evaluating is : 46.9435736677116 %.\n",
      "epoch number : 11\n",
      "[11,  1024] loss: 0.615\n",
      "[11,  2048] loss: 0.563\n",
      "[11,  3072] loss: 0.502\n",
      "[11,  4096] loss: 0.558\n",
      "[11,  5120] loss: 0.529\n",
      "[11,  6144] loss: 0.574\n",
      "[11,  7168] loss: 0.596\n",
      "[11,  8192] loss: 0.599\n",
      "[11,  9216] loss: 0.631\n",
      "[11, 10240] loss: 0.521\n",
      "[11, 11264] loss: 1.250\n",
      "accuray while evaluating is : 49.608150470219435 %.\n",
      "epoch number : 12\n",
      "[12,  1024] loss: 0.528\n",
      "[12,  2048] loss: 0.524\n",
      "[12,  3072] loss: 0.516\n",
      "[12,  4096] loss: 0.557\n",
      "[12,  5120] loss: 0.561\n",
      "[12,  6144] loss: 0.471\n",
      "[12,  7168] loss: 0.515\n",
      "[12,  8192] loss: 0.607\n",
      "[12,  9216] loss: 0.578\n",
      "[12, 10240] loss: 0.474\n",
      "[12, 11264] loss: 1.288\n",
      "accuray while evaluating is : 49.76489028213166 %.\n",
      "epoch number : 13\n",
      "[13,  1024] loss: 0.668\n",
      "[13,  2048] loss: 0.469\n",
      "[13,  3072] loss: 0.536\n",
      "[13,  4096] loss: 0.479\n",
      "[13,  5120] loss: 0.588\n",
      "[13,  6144] loss: 0.525\n",
      "[13,  7168] loss: 0.505\n",
      "[13,  8192] loss: 0.531\n",
      "[13,  9216] loss: 0.511\n",
      "[13, 10240] loss: 0.446\n",
      "[13, 11264] loss: 1.116\n",
      "accuray while evaluating is : 53.29153605015674 %.\n",
      "epoch number : 14\n",
      "[14,  1024] loss: 0.500\n",
      "[14,  2048] loss: 0.454\n",
      "[14,  3072] loss: 0.438\n",
      "[14,  4096] loss: 0.374\n",
      "[14,  5120] loss: 0.488\n",
      "[14,  6144] loss: 0.450\n",
      "[14,  7168] loss: 0.365\n",
      "[14,  8192] loss: 0.413\n",
      "[14,  9216] loss: 0.367\n",
      "[14, 10240] loss: 0.359\n",
      "[14, 11264] loss: 1.055\n",
      "accuray while evaluating is : 59.012539184952985 %.\n",
      "epoch number : 15\n",
      "[15,  1024] loss: 0.346\n",
      "[15,  2048] loss: 0.343\n",
      "[15,  3072] loss: 0.356\n",
      "[15,  4096] loss: 0.331\n",
      "[15,  5120] loss: 0.309\n",
      "[15,  6144] loss: 0.293\n",
      "[15,  7168] loss: 0.306\n",
      "[15,  8192] loss: 0.344\n",
      "[15,  9216] loss: 0.266\n",
      "[15, 10240] loss: 0.257\n",
      "[15, 11264] loss: 0.922\n",
      "accuray while evaluating is : 61.28526645768025 %.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#training\n",
    "update_weights = 1024\n",
    "loss_t = []\n",
    "acc = 0\n",
    "epoch_ = 15\n",
    "for epoch in range(epoch_):\n",
    "    running_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    print(\"epoch number :\",epoch+1)\n",
    "    for i,(x,y) in enumerate(total_data_):\n",
    "        model.train()\n",
    "        \n",
    "        h = model.init_hidden(1).to(device)\n",
    "        y = torch.LongTensor(y).to(device)\n",
    "        inp = torch.tensor(x.T,dtype = torch.long).to(device)\n",
    "        \n",
    "        try:\n",
    "            out = model(inp,h)\n",
    "            loss = loss_function(out,y)\n",
    "            loss.backward()\n",
    "            loss_t.append(running_loss)\n",
    "            running_loss += loss.item()\n",
    "        except: pass\n",
    "\n",
    "        if i % update_weights == update_weights - 1:    # update weights as defined\t\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss/update_weights ))\n",
    "            running_loss = 0\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    torch.save(model.state_dict(),\"weights/embed_\"+str(epoch)+\".pth\")\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        num = 0\n",
    "        length = 0\n",
    "        for i,(x,y) in enumerate(val_):\n",
    "            h = model.init_hidden(1).to(device)\n",
    "            y = torch.LongTensor(y).to(device)\n",
    "            inp = torch.tensor(x.T,dtype = torch.long).to(device)\n",
    "            try:\n",
    "                out = model(inp,h)\n",
    "                out,pred = torch.max(out,1)\n",
    "                if y == pred.item():\n",
    "                    num = num+1\n",
    "                length = length + 1\n",
    "            except: pass\n",
    "        accuracy = (num/length)*100\n",
    "        print(\"accuray while evaluating is :\",accuracy ,\"%.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuray while evaluating at0 is : 23.052464228934817 %.\n",
      "accuray while evaluating at1 is : 22.89348171701113 %.\n",
      "accuray while evaluating at2 is : 23.52941176470588 %.\n",
      "accuray while evaluating at3 is : 23.449920508744036 %.\n",
      "accuray while evaluating at4 is : 23.052464228934817 %.\n",
      "accuray while evaluating at5 is : 23.84737678855326 %.\n",
      "accuray while evaluating at6 is : 23.052464228934817 %.\n",
      "accuray while evaluating at7 is : 22.575516693163753 %.\n",
      "accuray while evaluating at8 is : 22.17806041335453 %.\n",
      "accuray while evaluating at9 is : 20.906200317965023 %.\n",
      "accuray while evaluating at10 is : 22.496025437201908 %.\n",
      "accuray while evaluating at11 is : 21.54213036565978 %.\n",
      "accuray while evaluating at12 is : 20.5087440381558 %.\n",
      "accuray while evaluating at13 is : 21.303656597774246 %.\n",
      "accuray while evaluating at14 is : 22.098569157392685 %.\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "for j in range(epoch_):\n",
    "    try:model.load_state_dict(torch.load(\"weights/embed_\"+str(j)+\".pth\"), strict = True)\n",
    "    except: pass\n",
    "    with torch.no_grad():\n",
    "            model.eval()\n",
    "            num = 0\n",
    "            length = 0\n",
    "            for i,(x,y) in enumerate(test_):\n",
    "                h = model.init_hidden(1).to(device)\n",
    "                y = torch.LongTensor(y).to(device)\n",
    "                inp = torch.tensor(x.T,dtype = torch.long).to(device)\n",
    "                try:\n",
    "                    out = model(inp,h)\n",
    "                    out,pred = torch.max(out,1)\n",
    "                    if y == pred.item():\n",
    "                        num = num+1\n",
    "                    length = length + 1\n",
    "                except: pass\n",
    "            accuracy = (num/length)*100\n",
    "            print(\"accuray while evaluating at\"+str(j)+\" is :\",accuracy,\"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total data bi \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
