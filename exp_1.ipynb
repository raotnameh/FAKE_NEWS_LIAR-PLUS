{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import plot as plt\n",
    "\n",
    "torch.manual_seed(1)\n",
    "from data import *\n",
    "import cleaningtool as ct\n",
    "from helpers import *\n",
    "\n",
    "from model import *\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning = True\n",
    "## Define paths\n",
    "DATA_FOLDER = './data_1/'\n",
    "TRAIN_PATH = DATA_FOLDER + 'train.tsv'\n",
    "TEST_PATH = DATA_FOLDER + 'test.tsv'\n",
    "VALID_PATH = DATA_FOLDER + 'valid.tsv'\n",
    "\n",
    "train_data = load_data(TRAIN_PATH)\n",
    "test_data = load_data(TEST_PATH)\n",
    "valid_data = load_data(VALID_PATH)\n",
    "\n",
    "\n",
    "train_data = train_data[[\"statement\", \"label\"]]\n",
    "test_data = test_data[[\"statement\", \"label\"]]\n",
    "valid_data = valid_data[[\"statement\", \"label\"]]\n",
    "\n",
    "df_raw = pd.concat([train_data, test_data, valid_data], axis=0, sort=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cleaning == True:\n",
    "    print(\"before :-\",df_raw[\"statement\"][0])\n",
    "    train_data = clean_data(train_data,\"statement\")\n",
    "    test_data = clean_data(test_data,\"statement\")\n",
    "    valid_data = clean_data(valid_data,\"statement\")\n",
    "    df_raw = clean_data(df_raw,'statement')\n",
    "    print()\n",
    "    print(\"after :-\", df_raw[\"statement\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To make BOW vector and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sent to Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_x, df_raw_y = sent_words(df_raw), sent_words(df_raw,label=True)\n",
    "x_train, y_train, x_val, y_val = sent_words(train_data), sent_words(train_data,label=True), sent_words(valid_data), sent_words(valid_data,label=True)\n",
    "x_test, y_test = sent_words(test_data), sent_words(test_data,label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train).reshape(len(x_train),1)\n",
    "y_train = np.array(y_train).reshape(len(x_train),1)\n",
    "x_test = np.array(x_test).reshape(len(x_test),1)\n",
    "y_test = np.array(y_test).reshape(len(x_test),1)\n",
    "x_val = np.array(x_val).reshape(len(x_val),1)\n",
    "y_val = np.array(y_val).reshape(len(x_val),1)\n",
    "\n",
    "train = np.concatenate((x_train,y_train),axis = 1)\n",
    "val = np.concatenate((x_val,y_val),axis = 1)\n",
    "test = np.concatenate((x_test,y_test),axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change it's value as per classification task requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of out classes, out\n",
    "out = 2\n",
    "word_to_ix = word_to_ix_(df_raw_x)\n",
    "if out == 2:\n",
    "    label_to_ix = {'true': 1, 'mostly-true': 1, 'half-true': 1, 'barely-true': 0, 'false': 0, 'pants-fire': 0}\n",
    "else:\n",
    "    label_to_ix = {'true': 5, 'mostly-true': 4, 'half-true': 3, 'barely-true': 2, 'false': 1, 'pants-fire': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating word_to_ix and label_to_ix dict and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_word = dict((v,k) for k,v in word_to_ix.items())\n",
    "ix_to_label = dict((v,k) for k,v in label_to_ix.items())\n",
    "VOCAB_SIZE = len( word_to_ix )\n",
    "NUM_LABELS = len(set(label_to_ix.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BoWClassifier(out,VOCAB_SIZE)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "try : model.load_state_dict(torch.load('BOW.pth'), strict = True)\n",
    "except : pass\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training\n",
    "update_weights = 512\n",
    "loss_t = []\n",
    "acc = 0\n",
    "epoch_ = 15\n",
    "for epoch in range(epoch_):\n",
    "    running_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    print(\"epoch number :\",epoch+1)\n",
    "    for i,(x,y) in enumerate(train):\n",
    "        model.train()\n",
    "\n",
    "        x,y = make_bow_vector(x,word_to_ix).to(device),make_target(y,label_to_ix).to(device)\n",
    "\n",
    "        out = model(x)\n",
    "\n",
    "        loss = loss_function(out,y)\n",
    "        loss.backward()\n",
    "        loss_t.append(running_loss)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        if i % update_weights == update_weights - 1:    # update weights as defined\t\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss/update_weights ))\n",
    "            running_loss = 0\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    torch.save(model.state_dict(),\"weights/EXP_\"+str(epoch)+\".pth\")\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        num = 0\n",
    "        length = 0\n",
    "        for x,y in val:\n",
    "            x,y = make_bow_vector(x,word_to_ix).to(device),make_target(y,label_to_ix).to(device)\n",
    "            out = model(x)\n",
    "            out,pred = torch.max(out,1)\n",
    "            if y == pred.item():\n",
    "                num = num+1\n",
    "            length = length + 1\n",
    "        accuracy = (num/length)*100\n",
    "        \n",
    "        print(\"accuray while evaluating is :\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "for j in range(epoch_):\n",
    "    with torch.no_grad():\n",
    "            model.eval()\n",
    "            num = 0\n",
    "            length = 0\n",
    "            model.load_state_dict(torch.load(\"weights/EXP_\"+str(j)+\".pth\"), strict = True)\n",
    "            for x,y in test:\n",
    "                x,y = make_bow_vector(x,word_to_ix).to(device),make_target(y,label_to_ix).to(device)\n",
    "                out = model(x)\n",
    "                out,pred = torch.max(out,1)\n",
    "                if y == pred.item():\n",
    "                    num = num+1\n",
    "                length = length + 1\n",
    "            accuracy = (num/length)*100\n",
    "            print(\"accuray while evaluating at\"+str(j)+\" is :\",accuracy,\"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
